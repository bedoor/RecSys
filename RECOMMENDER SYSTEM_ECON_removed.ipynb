{
 "metadata": {
  "name": "",
  "signature": "sha256:c2b2308e261de869f4d78725f7b67ab7bf53c93222701f5d806b9dd1fa9364ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import dask.dataframe as dd\n",
      "from dask.diagnostics import ProgressBar\n",
      "import pandas as pd\n",
      "\n",
      "field = \"Econ\"\n",
      "\n",
      "df = pd.read_csv(\"../data/\"+field+\"/\"+field+\"AIDPIDVIDANameVName.csv\")\n",
      "\n",
      "print df['AID'].nunique()\n",
      "print df['VID'].nunique()\n",
      "\n",
      "#df2 = df[['AID','VID','PID']].groupby(['AID','VID']).count().reset_index().rename(columns={\"PID\":\"Freq\"})\n",
      "\n",
      "df2 = df[['AID','VID']].drop_duplicates().groupby('AID').count().reset_index().rename(columns={\"VID\":\"VCount\"})\n",
      "\n",
      "df2 = df2[df2['VCount']>=5]\n",
      "\n",
      "print df2['AID'].nunique()\n",
      "\n",
      "df = df[df.AID.isin(df2['AID'])]\n",
      "\n",
      "print df.shape\n",
      "\n",
      "cit = pd.read_csv(\"../../Ethnic_Diversity/data/PaperCitations.csv\")\n",
      "cit.columns = ['PID','Citations']\n",
      "\n",
      "cit = cit[cit.PID.isin(df['PID'])]\n",
      "\n",
      "df = df.merge(cit, on='PID', how='left')\n",
      "\n",
      "df = df.fillna(0)\n",
      "\n",
      "print df.shape\n",
      "\n",
      "print df['AID'].nunique()\n",
      "print df['VID'].nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "V = df[['VID','VName']].drop_duplicates().reset_index(drop=True)\n",
      "V['Vindex'] = V.index\n",
      "\n",
      "A = df[['AID','AName']].drop_duplicates().reset_index(drop=True)\n",
      "A['Aindex'] = A.index\n",
      "\n",
      "A.to_csv(\"../data/\"+field+\"/\"+field+\"_Aindex.csv\", index=False)\n",
      "V.to_csv(\"../data/\"+field+\"/\"+field+\"_Vindex.csv\", index=False)\n",
      "\n",
      "data = df[['AID','VID','PID']].groupby(['AID','VID']).count().reset_index().rename(columns={\"PID\":\"Freq\"})\n",
      "\n",
      "data = data.merge(A, on=\"AID\")\n",
      "data = data.merge(V, on=\"VID\")\n",
      "\n",
      "data.to_csv(\"../data/\"+field+\"/\"+field+\"_data.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PC = pd.read_csv(\"../data/PaperPubYear.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PC2 = PC[PC.PID.isin(df['PID'])]\n",
      "\n",
      "df = df.merge(PC2, on=\"PID\")\n",
      "\n",
      "print df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['AnnualCitations'] = 2017 - df['PubYear']\n",
      "df['Citations'] = df['Citations'].astype(float)\n",
      "df['AnnualCitations'] = df['AnnualCitations'].astype(float)\n",
      "df['AnnualCitations'] = df['Citations'] / df['AnnualCitations']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = df[['AID','VID','AnnualCitations']].groupby(['AID','VID']).mean().reset_index().rename(columns={'AnnualCitations':'AvgAnnualCitations'})\n",
      "print all_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.merge(data, all_data, how='inner', on=['AID','VID'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AIDMaxCit = data.groupby('AID')['AvgAnnualCitations'].max().reset_index(name=\"maxCitation\")\n",
      "\n",
      "data = data.merge(AIDMaxCit, on='AID') \n",
      "\n",
      "data['NormCitation'] = data['AvgAnnualCitations'] / data['maxCitation']\n",
      "\n",
      "data['NormCitation2'] = data['NormCitation']*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for specific data separation of test vs train. 5 rankings from each author for testing purposes.\n",
      "\n",
      "#extract 3 rankings for each author as the test data\n",
      "test = data.groupby('AID', as_index=False).apply(lambda x: x.sample(n=2, replace=False)).reset_index(drop=True)\n",
      "print test.shape\n",
      "\n",
      "#all remaining data is for training purposes\n",
      "train= pd.merge(data, test, how='outer', indicator=True).query(\"_merge == 'left_only'\").drop('_merge',1)\n",
      "\n",
      "print train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### FOR AVG CITATIONS RATING ########\n",
      "n_venues = max(train['Vindex'].max(), test['Vindex'].max()) + 1\n",
      "n_authors = max(train['Aindex'].max(), test['Aindex'].max()) + 1\n",
      "\n",
      "#Calc vars of matrices  \n",
      "Rrows, Rcols = (n_authors, n_venues)\n",
      "print Rrows, Rcols\n",
      "\n",
      "Rx = train['Aindex'].values#.astype(int)\n",
      "Ry = train['Vindex'].values#.astype(int)\n",
      "#Rdata = ((train['AvgAnnualCitations'].values / max_citation)*0.2 + (train['VFreq'].values / max_vfreq)*0.8)\n",
      "#Rdata = train['NormCitation2'].values \n",
      "Rdata = train['NormCitation'].values\n",
      "\n",
      "Trows, Tcols = (n_authors, n_venues)\n",
      "print Trows, Tcols\n",
      "\n",
      "Tx = test['Aindex'].values\n",
      "Ty = test['Vindex'].values\n",
      "#Tdata = (test['AvgAnnualCitations'].values / max_citation)*0.2 + (test['VFreq'].values / max_vfreq)*0.8\n",
      "#Tdata = test['NormCitation2'].values\n",
      "Tdata = test['NormCitation'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "#recreate R and T matrices\n",
      "R = np.zeros((Rrows, Rcols))\n",
      "for i,j,k in zip(Rx,Ry,Rdata):\n",
      "    if k>0:\n",
      "        R[i,j] = k\n",
      "    \n",
      "T = np.zeros((Trows, Tcols))\n",
      "for i,j,k in zip(Tx,Ty,Tdata):\n",
      "    if k>0:\n",
      "        T[i,j] = k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Index matrix for training data\n",
      "I = R.copy()\n",
      "I[I > 0] = 1\n",
      "I[I == 0] = 0\n",
      "\n",
      "# Index matrix for test data\n",
      "I2 = T.copy()\n",
      "I2[I2 > 0] = 1\n",
      "I2[I2 == 0] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict the unknown ratings through the dot product of the latent features for users and items \n",
      "def prediction(P,Q):\n",
      "    return np.dot(P.T,Q)\n",
      "\n",
      "def predictionBias(P,Q,mu, bu, bi):\n",
      "    return mu + bu + bi + np.dot(P.T,Q)\n",
      "\n",
      "def predictionBias2(P,Q,mu, bu, bi):\n",
      "    return mu + np.vstack(bu) + bi + np.dot(P.T,Q)\n",
      "\n",
      "# Calculate the RMSE\n",
      "def rmse(I,R,Q,P):\n",
      "    return np.sqrt(np.sum((I * (R - prediction(P,Q)))**2)/len(R[R > 0]))\n",
      "\n",
      "def rmseBias(I,R,Q,P,mu,bu,bi):\n",
      "    return np.sqrt(np.sum((I * (R - mu - bi - np.vstack(bu) - prediction(P,Q)))**2)/len(R[R > 0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#################### Rec Sys For Citation RATING with BIASES###########################\n",
      "\n",
      "##### COMPUTER SCIENCE ####\n",
      "\n",
      "lmbda = 0.2 # Regularisation weight \n",
      "k = 20  # Dimension of the latent feature space\n",
      "m, n = R.shape  # Number of users and items\n",
      "n_epochs = 1000 # Number of epochs\n",
      "gamma= 0.00005  # Learning rate  \n",
      "\n",
      "lmbda2 = 0.2 #Regularisation weight for biases\n",
      "gamma2 = 0.00005 # Learning rate for biases \n",
      "\n",
      "\n",
      "############\n",
      "\n",
      "P = np.random.rand(k,m) # Latent author feature matrix\n",
      "Q = np.random.rand(k,n) # Latent venue feature matrix\n",
      "bu = np.zeros(m)            # Bias vector users\n",
      "bi = np.zeros(n)            # Bias vector items\n",
      "\n",
      "# mu  is overall average rating\n",
      "mu = (sum(Rdata) + sum(Tdata)) / (float(len(Rdata)) + float(len(Tdata)))\n",
      "\n",
      "train_errors = []\n",
      "test_errors = []\n",
      "\n",
      "#Only consider non-zero matrix \n",
      "authors,venues = R.nonzero()  \n",
      "\n",
      "############\n",
      "\n",
      "old_train_rmse = 1000000\n",
      "old_test_rmse = 1000000\n",
      "\n",
      "for epoch in xrange(n_epochs):\n",
      "    print epoch\n",
      "    for u, i in zip(authors,venues):\n",
      "        e = R[u, i] - predictionBias(P[:,u],Q[:,i],mu,bu[u],bi[i])  # Calculate error for gradient\n",
      "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent author feature matrix\n",
      "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # Update latent venue feature matrix\n",
      "        bu[u] += gamma2 * (e - lmbda2 * bu[u])\n",
      "        bi[i] += gamma2 * (e - lmbda2 * bi[i])\n",
      "    Q = np.nan_to_num(Q)\n",
      "    P = np.nan_to_num(P)\n",
      "    train_rmse = rmseBias(I,R,Q,P,mu,bu,bi) # Calculate root mean squared error from train dataset\n",
      "    test_rmse = rmseBias(I2,T,Q,P,mu,bu,bi) # Calculate root mean squared error from test dataset\n",
      "    train_errors.append(train_rmse)\n",
      "    test_errors.append(test_rmse)\n",
      "    print \"train RMSE: \", train_rmse\n",
      "    print \"test RMSE: \", test_rmse\n",
      "    if test_rmse > old_test_rmse:\n",
      "        break\n",
      "    old_test_rmse = test_rmse\n",
      "    \n",
      "    if train_rmse > old_train_rmse:\n",
      "        break\n",
      "    old_train_rmse = train_rmse\n",
      "    \n",
      "    \n",
      "print P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#################### Rec Sys For Citation RATING with BIASES###########################\n",
      "\n",
      "##### COMPUTER SCIENCE ####\n",
      "\n",
      "lmbda = 0.3 # Regularisation weight \n",
      "k = 20  # Dimension of the latent feature space\n",
      "m, n = R.shape  # Number of users and items\n",
      "n_epochs = 10000 # Number of epochs\n",
      "gamma= 0.00005  # Learning rate  \n",
      "\n",
      "lmbda2 = 0.3 #Regularisation weight for biases\n",
      "gamma2 = 0.00005 # Learning rate for biases \n",
      "\n",
      "\n",
      "############\n",
      "'''\n",
      "P = np.random.rand(k,m) # Latent author feature matrix\n",
      "Q = np.random.rand(k,n) # Latent venue feature matrix\n",
      "bu = np.zeros(m)            # Bias vector users\n",
      "bi = np.zeros(n)            # Bias vector items\n",
      "\n",
      "# mu  is overall average rating\n",
      "mu = (sum(Rdata) + sum(Tdata)) / (float(len(Rdata)) + float(len(Tdata)))\n",
      "\n",
      "train_errors = []\n",
      "test_errors = []\n",
      "\n",
      "#Only consider non-zero matrix \n",
      "authors,venues = R.nonzero()  \n",
      "'''\n",
      "############\n",
      "\n",
      "old_train_rmse = 1000000\n",
      "old_test_rmse = 1000000\n",
      "\n",
      "for epoch in xrange(n_epochs):\n",
      "    print epoch\n",
      "    for u, i in zip(authors,venues):\n",
      "        e = R[u, i] - predictionBias(P[:,u],Q[:,i],mu,bu[u],bi[i])  # Calculate error for gradient\n",
      "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent author feature matrix\n",
      "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # Update latent venue feature matrix\n",
      "        bu[u] += gamma2 * (e - lmbda2 * bu[u])\n",
      "        bi[i] += gamma2 * (e - lmbda2 * bi[i])\n",
      "    Q = np.nan_to_num(Q)\n",
      "    P = np.nan_to_num(P)\n",
      "    train_rmse = rmseBias(I,R,Q,P,mu,bu,bi) # Calculate root mean squared error from train dataset\n",
      "    test_rmse = rmseBias(I2,T,Q,P,mu,bu,bi) # Calculate root mean squared error from test dataset\n",
      "    train_errors.append(train_rmse)\n",
      "    test_errors.append(test_rmse)\n",
      "    print \"train RMSE: \", train_rmse\n",
      "    print \"test RMSE: \", test_rmse\n",
      "    if test_rmse > old_test_rmse:\n",
      "        break\n",
      "    old_test_rmse = test_rmse\n",
      "    \n",
      "    if train_rmse > old_train_rmse:\n",
      "        break\n",
      "    old_train_rmse = train_rmse\n",
      "    \n",
      "    \n",
      "print P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Calc vars of matrices to save    \n",
      "Rdim = R.shape\n",
      "Rx, Ry = R.nonzero()\n",
      "Rdata = R[Rx,Ry]\n",
      "\n",
      "Tdim = T.shape\n",
      "Tx, Ty = T.nonzero()\n",
      "Tdata = T[Tx,Ty]\n",
      "\n",
      "Pdim = P.shape\n",
      "Px, Py = P.nonzero()\n",
      "Pdata = P[Px,Py]\n",
      "\n",
      "Qdim = Q.shape\n",
      "Qx, Qy = Q.nonzero()\n",
      "Qdata = Q[Qx,Qy]\n",
      "\n",
      "file_extension = \"Citations_\"+field\n",
      "#Save Matrix info (dimension, nonzero x and y indices and data) for future  use\n",
      "np.savetxt(\"../data/\"+field+\"/R_dimension\"+file_extension+\".txt\",Rdim)\n",
      "np.savetxt(\"../data/\"+field+\"/R_x\"+file_extension+\".txt\", Rx)\n",
      "np.savetxt(\"../data/\"+field+\"/R_y\"+file_extension+\".txt\", Ry)\n",
      "np.savetxt(\"../data/\"+field+\"/R_data\"+file_extension+\".txt\", Rdata)\n",
      "\n",
      "#Save Matrix info (dimension, nonzero x and y indices and data) for future  use\n",
      "np.savetxt(\"../data/\"+field+\"/T_dimension\"+file_extension+\".txt\",Tdim)\n",
      "np.savetxt(\"../data/\"+field+\"/T_x\"+file_extension+\".txt\", Tx)\n",
      "np.savetxt(\"../data/\"+field+\"/T_y\"+file_extension+\".txt\", Ty)\n",
      "np.savetxt(\"../data/\"+field+\"/T_data\"+file_extension+\".txt\", Tdata)\n",
      "\n",
      "#Save Matrix info (dimension, nonzero x and y indices and data) for future  use\n",
      "np.savetxt(\"../data/\"+field+\"/P_dimension\"+file_extension+\".txt\",Pdim)\n",
      "np.savetxt(\"../data/\"+field+\"/P_x\"+file_extension+\".txt\", Px)\n",
      "np.savetxt(\"../data/\"+field+\"/P_y\"+file_extension+\".txt\", Py)\n",
      "np.savetxt(\"../data/\"+field+\"/P_data\"+file_extension+\".txt\", Pdata)\n",
      "\n",
      "#Save Matrix info (dimension, nonzero x and y indices and data) for future  use\n",
      "np.savetxt(\"../data/\"+field+\"/Q_dimension\"+file_extension+\".txt\",Qdim)\n",
      "np.savetxt(\"../data/\"+field+\"/Q_x\"+file_extension+\".txt\", Qx)\n",
      "np.savetxt(\"../data/\"+field+\"/Q_y\"+file_extension+\".txt\", Qy)\n",
      "np.savetxt(\"../data/\"+field+\"/Q_data\"+file_extension+\".txt\", Qdata)\n",
      "\n",
      "#save b_i, b_u and mu\n",
      "np.savetxt(\"../data/\"+field+\"/b_i\"+file_extension+\".txt\",bi)\n",
      "np.savetxt(\"../data/\"+field+\"/b_u\"+file_extension+\".txt\", bu)\n",
      "np.savetxt(\"../data/\"+field+\"/mu\"+file_extension+\".txt\", (mu,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#################### SIMPLER Rec Sys For Citation RATING without BIASES###########################\n",
      "\n",
      "lmbda = 0.8 # Regularisation weight \n",
      "k = 10 # Dimension of the latent feature space\n",
      "m, n = R.shape  # Number of users and items\n",
      "n_epochs = 10000 # Number of epochs\n",
      "gamma= 0.000005  # Learning rate  \n",
      "\n",
      "\n",
      "#P = np.random.rand(k,m) # Latent author feature matrix\n",
      "#Q = np.random.rand(k,n) # Latent venue feature matrix\n",
      "\n",
      "#train_errors = []\n",
      "#test_errors = []\n",
      "\n",
      "#Only consider non-zero matrix \n",
      "#authors,venues = R.nonzero()\n",
      "\n",
      "old_test_rmse = 10000000\n",
      "\n",
      "for epoch in xrange(n_epochs):\n",
      "    print epoch\n",
      "    for u, i in zip(authors,venues):\n",
      "        e = R[u, i] - prediction(P[:,u],Q[:,i])  # Calculate error for gradient\n",
      "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent user feature matrix\n",
      "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # Update latent movie feature matrix\n",
      "    train_rmse = rmse(I,R,Q,P) # Calculate root mean squared error from train dataset\n",
      "    test_rmse = rmse(I2,T,Q,P) # Calculate root mean squared error from test dataset\n",
      "    train_errors.append(train_rmse)\n",
      "    test_errors.append(test_rmse)\n",
      "    print \"train RMSE: \", train_rmse\n",
      "    print \"test RMSE: \", test_rmse\n",
      "    if test_rmse > old_test_rmse:\n",
      "        break\n",
      "    old_test_rmse = test_rmse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}